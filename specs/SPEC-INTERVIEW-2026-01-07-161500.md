# TalkFlow Local Transcription Feature Specification

**Interview Date:** 2026-01-07
**Feature:** Local Speech-to-Text using WhisperKit
**Status:** Ready for Implementation

---

## 1. Overview

This specification covers the implementation of local, on-device speech-to-text transcription for TalkFlow using WhisperKit. Users will be able to download Whisper models and transcribe audio entirely locally without sending data to OpenAI's API, while maintaining the same user experience (press-and-hold to record, release to transcribe and paste).

### Key Goals
- Provide privacy-focused alternative to cloud transcription
- Support multiple model sizes for quality/size tradeoffs
- Seamless switching between API and local modes
- No change to core user workflow

---

## 2. Requirements

### Functional Requirements

| ID | Requirement | Priority |
|----|-------------|----------|
| FR-1 | Users can switch between OpenAI API and local transcription modes | Must |
| FR-2 | Users can choose from 3 model tiers: tiny (~40MB), small (~250MB), large-v3-turbo (~800MB) | Must |
| FR-3 | Model download shows progress bar with percentage | Must |
| FR-4 | Users must explicitly choose a model before download begins | Must |
| FR-5 | Downloaded models can be deleted from within the app | Must |
| FR-6 | Recording/transcription is blocked during model download | Must |
| FR-7 | Users can configure preferred language (with auto-detect option) | Must |
| FR-8 | Model load errors block transcription and notify user | Must |
| FR-9 | "Test Transcription" button records 3-sec clip and transcribes | Should |
| FR-10 | Model version tracking with in-settings update indicator | Should |
| FR-11 | Word-level timestamps and confidence stored for future features | Should |

### Non-Functional Requirements

| ID | Requirement |
|----|-------------|
| NFR-1 | Mode switching is immediate (no app restart required) |
| NFR-2 | Models stored in WhisperKit's default cache location |
| NFR-3 | No additional entitlements required beyond current set |
| NFR-4 | Full error detail logging for WhisperKit operations |
| NFR-5 | Model auto-detection of optimal compute unit (ANE/GPU/CPU) |

---

## 3. Technical Decisions

### Framework Choice: WhisperKit

**Decision:** Use [WhisperKit](https://github.com/argmaxinc/WhisperKit) by Argmax

**Rationale:**
- Native Swift package, integrates directly via SPM
- Uses CoreML for Apple Silicon optimization
- Mature, actively maintained
- Supports streaming, VAD, word timestamps
- Auto-downloads models from HuggingFace
- No additional entitlements required

**Alternatives Considered:**
- mlx-whisper: Python-only, not suitable for native Swift app
- swift-transformers (HuggingFace): Newer, less mature for Whisper specifically

### Architecture: TranscriptionRouter Pattern

**Decision:** Create a `TranscriptionRouter` that internally manages both `OpenAIWhisperService` and `LocalTranscriptionService`, delegating based on configuration.

**Rationale:**
- Enables immediate mode switching without app restart
- Both services initialized and ready (router decides which to use)
- Single injection point in DependencyContainer
- Conforms to existing `TranscriptionService` protocol

```
┌─────────────────────────────────────────────────────────────┐
│                    TranscriptionRouter                       │
│                 (implements TranscriptionService)            │
│                                                              │
│  ┌──────────────────────┐    ┌───────────────────────────┐  │
│  │ OpenAIWhisperService │    │ LocalTranscriptionService │  │
│  │    (cloud API)       │    │    (WhisperKit)           │  │
│  └──────────────────────┘    └───────────────────────────┘  │
│                                                              │
│  Configuration.transcriptionMode → selects active service    │
└─────────────────────────────────────────────────────────────┘
```

### Model Tiers

| Model | Size | Quality | Use Case |
|-------|------|---------|----------|
| tiny | ~40MB | Basic | Quick tests, low storage |
| small | ~250MB | Good | Balanced quality/size |
| large-v3-turbo | ~800MB | Best | Maximum accuracy |

### Memory Management

**Decision:** Load model on first use, keep loaded during app runtime.

**Rationale:**
- Model load takes 1-5+ seconds depending on size
- First transcription will experience this delay
- Subsequent transcriptions are fast
- Memory usage acceptable for menu bar app (500MB-2GB depending on model)
- Simpler than implementing load/unload lifecycle

### Storage Locations

| Data | Location |
|------|----------|
| Models | WhisperKit default (`~/Library/Caches/com.argmax.whisperkit.models/`) |
| Configuration | UserDefaults (via ConfigurationManager) |
| Transcription history | `~/Library/Application Support/TalkFlow/transcriptions.sqlite` |

---

## 4. Data Model

### Configuration Changes (AppConfiguration)

```swift
struct AppConfiguration: Codable, Sendable {
    // Existing fields...

    // New fields for local transcription
    var transcriptionMode: TranscriptionMode = .api  // .api or .local
    var selectedLocalModel: String? = nil  // e.g., "openai_whisper-tiny"
    var transcriptionLanguage: String = "auto"  // ISO code or "auto"
}

enum TranscriptionMode: String, Codable, Sendable {
    case api
    case local
}
```

### Database Schema Changes (TranscriptionRecord)

Add three new columns to `transcriptions` table:

```sql
ALTER TABLE transcriptions ADD COLUMN source TEXT;  -- "api" or "local"
ALTER TABLE transcriptions ADD COLUMN model TEXT;   -- model identifier
ALTER TABLE transcriptions ADD COLUMN metadata TEXT; -- JSON blob for timestamps, etc.
```

```swift
struct TranscriptionRecord: Codable, Identifiable, FetchableRecord, PersistableRecord {
    var id: String
    var text: String
    var timestamp: Date
    var durationMs: Int?
    var confidence: Double?
    var createdAt: Date

    // New fields
    var source: String?      // "api" or "local"
    var model: String?       // "whisper-1" or "openai_whisper-small"
    var metadata: String?    // JSON: word timestamps, per-word confidence, etc.
}
```

### Metadata JSON Schema

```json
{
  "wordTimestamps": [
    {"word": "hello", "start": 0.0, "end": 0.5, "confidence": 0.98},
    {"word": "world", "start": 0.6, "end": 1.0, "confidence": 0.95}
  ],
  "language": "en",
  "languageConfidence": 0.99
}
```

---

## 5. User Flows

### Flow 1: Enable Local Transcription (First Time)

```
1. User opens Settings
2. User sees "Transcription" section with API key input
3. User toggles "Use local model" switch ON
4. Toggle stays OFF, inline section expands showing:
   - Model picker (tiny, small, large-v3-turbo) with sizes
   - "Download" button (disabled until selection)
5. User selects "small (~250MB)"
6. User clicks "Download"
7. Progress bar appears: "Downloading small model... 45%"
8. Recording shortcut is disabled (visual indicator in UI)
9. Download completes
10. Toggle switches ON, section shows:
    - Selected model: "small" with checkmark
    - "Delete" button
    - Recording shortcut re-enabled
11. User can now use local transcription
```

### Flow 2: Switch Between Modes

```
1. User has local model downloaded and API key configured
2. User toggles "Use local model" OFF
3. Immediately switches to API mode (no restart)
4. Next transcription uses OpenAI API
5. User toggles "Use local model" ON
6. Immediately switches to local mode
7. Next transcription uses local model
```

### Flow 3: Model Load Failure

```
1. User has local mode enabled with "small" model selected
2. User deleted model files manually from Finder
3. User triggers recording
4. System detects model files missing
5. Error shown: "Local model not found. Please re-download or switch to API mode."
6. User must either:
   a. Re-download the model, OR
   b. Switch to API mode
7. No automatic fallback to API
```

### Flow 4: Download Failure

```
1. User starts model download
2. Network disconnects mid-download
3. Error shown: "Download failed: Network error"
4. Partial files deleted (clean restart approach)
5. User can retry download
6. Fresh download begins from 0%
```

### Flow 5: Test Transcription

```
1. User has local model downloaded
2. User clicks "Test Transcription" button in settings
3. Button changes to "Recording... (3s)"
4. Records 3 seconds of audio
5. Button changes to "Transcribing..."
6. Result shown in alert/popover: "Transcribed: [text]"
7. Confirms model is working
```

### Flow 6: Model Update Available

```
1. App checks for model updates on launch (background)
2. If newer version exists for downloaded model
3. Settings shows indicator: "Update available" next to model
4. User can click to download update
5. Old model replaced with new version
```

---

## 6. Edge Cases

| Scenario | Behavior |
|----------|----------|
| User toggles local mode with no model downloaded | Inline section expands, toggle stays OFF until download completes |
| Download interrupted by app quit | Partial files deleted on next launch, must re-download |
| Model files corrupted | Load error detected, user notified, must re-download |
| Disk full during download | Error shown with disk space info, download cancelled |
| Recording attempted during download | Blocked entirely, UI shows download progress |
| Switch mode mid-transcription | Wait for current transcription to complete, next uses new mode |
| Multiple rapid mode switches | Each switch is immediate, last setting wins |
| First transcription after app launch | May have 1-5s delay while model loads (load on first use) |
| Model selected but not downloaded | "Download required" state, can't use local mode |

---

## 7. Error Handling

### Error Types

```swift
enum LocalTranscriptionError: Error {
    case modelNotDownloaded
    case modelLoadFailed(underlying: Error)
    case modelCorrupted
    case transcriptionFailed(underlying: Error)
    case downloadFailed(underlying: Error)
    case insufficientDiskSpace(required: Int64, available: Int64)
    case networkUnavailable
}
```

### Error Messages (User-Facing)

| Error | Message |
|-------|---------|
| modelNotDownloaded | "Local model not downloaded. Please download a model in Settings." |
| modelLoadFailed | "Failed to load local model. Try re-downloading or switch to API mode." |
| modelCorrupted | "Local model files are corrupted. Please delete and re-download." |
| transcriptionFailed | "Local transcription failed. Check logs for details." |
| downloadFailed | "Model download failed: [reason]. Please try again." |
| insufficientDiskSpace | "Not enough disk space. Need [X] MB, have [Y] MB available." |
| networkUnavailable | "No network connection. Cannot download model." |

### Logging Strategy

All WhisperKit operations logged with full detail:
- Model download progress and errors
- Model load timing and errors
- Transcription timing and errors
- Compute unit selection (ANE/GPU/CPU)
- Memory usage during transcription

Log location: `~/Library/Logs/TalkFlow/talkflow.log`

---

## 8. Open Questions

None - all questions resolved during interview.

---

## 9. Out of Scope

| Item | Reason |
|------|--------|
| Crash recovery for in-progress audio | Accepted as same behavior as current API mode |
| Automatic API fallback on local failure | User explicitly chose local mode |
| Model warmup optimization | Natural delay on first use accepted |
| Parallel model downloads | Simpler UX with one-at-a-time |
| User-configurable storage path | Use WhisperKit defaults |
| macOS notification for updates | In-settings indicator only |
| Real-time streaming transcription | Future enhancement |
| Custom model imports | Future enhancement |

---

## 10. Phased Implementation Plan

### Phase 1: Core Infrastructure (Foundation)

**Goal:** Establish the service architecture and configuration without UI changes.

**Scope:**
- Add WhisperKit SPM dependency
- Create `LocalTranscriptionService` conforming to `TranscriptionService` protocol
- Create `TranscriptionRouter` that delegates to appropriate service
- Add new configuration fields to `AppConfiguration`
- Update database schema with new columns (source, model, metadata)
- Update `TranscriptionRecord` struct

**Dependencies/Prerequisites:**
- None (starting point)

**Deliverables:**
- `LocalTranscriptionService.swift` - WhisperKit wrapper
- `TranscriptionRouter.swift` - routing logic
- Updated `Configuration.swift` with new fields
- Database migration in `HistoryStorage.swift`
- Updated `TranscriptionRecord.swift`
- Unit tests for new services

**Acceptance Criteria:**
- [ ] WhisperKit compiles and links successfully
- [ ] `LocalTranscriptionService` can load a model and transcribe audio (manual test)
- [ ] `TranscriptionRouter` correctly delegates based on configuration
- [ ] New config fields persist across app restarts
- [ ] Database migration runs without data loss
- [ ] Existing transcriptions continue to work
- [ ] All existing tests pass

**Risks & Mitigations:**
1. WhisperKit API changes - Pin to specific version
2. Database migration issues - Add migration tests, backup strategy

---

### Phase 2: Model Management Service

**Goal:** Implement model download, storage, and lifecycle management.

**Scope:**
- Create `ModelManager` class for download/delete/status operations
- Implement download progress tracking with cancellation
- Implement model existence and integrity checking
- Implement model deletion
- Add model version tracking
- Handle download failures with clean restart

**Dependencies/Prerequisites:**
- Phase 1 complete

**Deliverables:**
- `ModelManager.swift` - download, delete, status operations
- `ModelInfo.swift` - model metadata struct
- Download progress callback mechanism
- Model integrity verification logic
- Unit tests for model management

**Acceptance Criteria:**
- [ ] Can download each model tier successfully
- [ ] Download shows accurate progress percentage
- [ ] Download can be cancelled, partial files cleaned up
- [ ] Failed downloads clean up partial files
- [ ] Downloaded models can be deleted
- [ ] Model existence check works correctly
- [ ] Model version is tracked

**Risks & Mitigations:**
1. Large download reliability - Implement timeout handling, clear error messages
2. Disk space issues - Check available space before download

---

### Phase 3: Settings UI Integration

**Goal:** Add local transcription controls to Settings.

**Scope:**
- Add "Use local model" toggle to TranscriptionSettingsView
- Add inline model picker (expanded when toggle attempted with no model)
- Add download progress UI
- Add model delete button
- Add language preference picker
- Disable toggle until model is downloaded
- Show update available indicator

**Dependencies/Prerequisites:**
- Phase 1 and 2 complete

**Deliverables:**
- Updated `TranscriptionSettingsView.swift`
- `LocalModelPickerView.swift` - model selection UI
- `ModelDownloadProgressView.swift` - progress indicator
- Integration with `ModelManager`

**Acceptance Criteria:**
- [ ] Toggle appears in correct location (inline with API config)
- [ ] Toggle disabled until model downloaded
- [ ] Model picker shows all 3 tiers with sizes
- [ ] Download progress bar shows percentage
- [ ] Delete button removes model and resets toggle
- [ ] Language picker works and persists
- [ ] Update indicator shows when available
- [ ] UI follows existing design patterns (DesignConstants)

**Risks & Mitigations:**
1. UI complexity - Keep inline expansion simple, test on various window sizes

---

### Phase 4: Recording Flow Integration

**Goal:** Connect local transcription to the main recording workflow.

**Scope:**
- Update `DependencyContainer` to use `TranscriptionRouter`
- Block recording during model download (disable shortcut)
- Handle model load on first transcription
- Store transcription source/model in history
- Immediate mode switching (no restart)

**Dependencies/Prerequisites:**
- Phases 1-3 complete

**Deliverables:**
- Updated `DependencyContainer.swift`
- Updated `ShortcutManager` for download-blocking state
- Recording state management during downloads
- History records include source/model/metadata

**Acceptance Criteria:**
- [ ] Recording uses correct service based on mode
- [ ] Mode switch is immediate (no restart)
- [ ] Recording blocked during download with clear indication
- [ ] First transcription works (with model load delay)
- [ ] History shows transcription source
- [ ] Word timestamps stored in metadata field
- [ ] No regression in API transcription flow

**Risks & Mitigations:**
1. Mode switch race conditions - Serialize transcription requests
2. First-use delay UX - Accept delay, document in UI

---

### Phase 5: Test Transcription & Polish

**Goal:** Add test functionality and polish the feature.

**Scope:**
- Add "Test Transcription" button that records 3s and transcribes
- Comprehensive error handling and user messaging
- Full logging integration
- Edge case handling (missing files, corrupt model, etc.)
- Performance optimization review

**Dependencies/Prerequisites:**
- Phases 1-4 complete

**Deliverables:**
- Test transcription button in settings
- Polished error messages for all failure modes
- Complete logging coverage
- Documentation updates (README, SPEC.md)

**Acceptance Criteria:**
- [ ] Test button records and transcribes successfully
- [ ] All error cases show appropriate messages
- [ ] Logs capture all WhisperKit operations
- [ ] Manual QA of full user flows passes
- [ ] Documentation updated

**Risks & Mitigations:**
1. Test recording conflicts with main recording - Use same audio service, serialize

---

## 11. Implementation Notes

### WhisperKit Integration

```swift
import WhisperKit

class LocalTranscriptionService: TranscriptionService {
    private var whisperKit: WhisperKit?
    private let modelManager: ModelManager

    func transcribe(audio: Data) async throws -> TranscriptionResult {
        // Ensure model is loaded
        if whisperKit == nil {
            whisperKit = try await WhisperKit(
                model: modelManager.selectedModelPath,
                computeOptions: .init()  // Auto-detect best compute unit
            )
        }

        // Convert audio data to format WhisperKit expects
        let audioPath = try saveToTempFile(audio)
        defer { try? FileManager.default.removeItem(atPath: audioPath) }

        // Transcribe
        let result = try await whisperKit!.transcribe(audioPath: audioPath)

        return TranscriptionResult(
            text: result.text,
            confidence: result.avgLogprob.map { exp($0) },
            language: result.language,
            duration: result.timings?.audioProcessing
        )
    }
}
```

### Model Download with Progress

```swift
class ModelManager {
    func downloadModel(_ model: WhisperModel, progress: @escaping (Double) -> Void) async throws {
        // WhisperKit handles download internally
        // We wrap it to provide progress updates

        let config = WhisperKitConfig(
            model: model.identifier,
            downloadProgress: { downloadProgress in
                progress(downloadProgress.fractionCompleted)
            }
        )

        _ = try await WhisperKit(config)
    }
}
```

### TranscriptionRouter Pattern

```swift
class TranscriptionRouter: TranscriptionService {
    private let openAIService: OpenAIWhisperService
    private let localService: LocalTranscriptionService
    private let configurationManager: ConfigurationManager

    func transcribe(audio: Data) async throws -> TranscriptionResult {
        switch configurationManager.configuration.transcriptionMode {
        case .api:
            return try await openAIService.transcribe(audio: audio)
        case .local:
            return try await localService.transcribe(audio: audio)
        }
    }
}
```

### Database Migration

```swift
// In HistoryStorage.setupDatabase()
migrator.registerMigration("addTranscriptionSource") { db in
    try db.alter(table: "transcriptions") { t in
        t.add(column: "source", .text)
        t.add(column: "model", .text)
        t.add(column: "metadata", .text)
    }
}
```

---

## 12. Testing Strategy

### Unit Tests
- `LocalTranscriptionServiceTests` - mock WhisperKit, test error handling
- `TranscriptionRouterTests` - verify routing logic
- `ModelManagerTests` - download state management
- `ConfigurationTests` - new fields persist correctly
- `HistoryStorageTests` - migration, new fields saved/loaded

### Integration Tests
- Full transcription flow with local model
- Mode switching mid-session
- Download interruption and retry

### Manual Testing Checklist
- [ ] Fresh install: API mode works
- [ ] Download each model tier
- [ ] Switch modes multiple times
- [ ] Delete and re-download model
- [ ] Transcribe with each model
- [ ] Test transcription button
- [ ] Force-quit during download
- [ ] Delete model files from Finder, verify error handling

---

## Sources

- [WhisperKit GitHub](https://github.com/argmaxinc/WhisperKit)
- [WhisperKit Swift Package Index](https://swiftpackageindex.com/argmaxinc/WhisperKit)
- [WhisperKit Benchmarks](https://huggingface.co/spaces/argmaxinc/whisperkit-benchmarks)
- [M4 Whisper Performance Analysis](https://dev.to/theinsyeds/whisper-speech-recognition-on-mac-m4-performance-analysis-and-benchmarks-2dlp)
